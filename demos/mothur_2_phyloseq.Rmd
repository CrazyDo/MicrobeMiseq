---
title: "Microbial Community Diversity Analysis Tutorial with Phyloseq"
output:
  html_document:
    toc: true
    toc_float: true
---
This is a demo of how to import amplicon microbiome data into R using [Phyloseq](http://joey711.github.io/phyloseq/) and run some basic analyses to 
understand microbial community diversity and composition accross your samples. 
More demos of this package are available from the authors [here](http://joey711.github.io/phyloseq-demo/phyloseq-demo.html). 
This script was created with [Rmarkdown](http://rmarkdown.rstudio.com/).

Author: Michelle Berry     
Updated: April 14, 2016 

===================================================================

In this tutorial, we are working with illumina 16s data that has already been processed into an [OTU](https://en.wikipedia.org/wiki/Operational_taxonomic_unit) and taxonomy table from the [mothur](http://www.mothur.org/) pipeline. Phyloseq has a variety of [import](http://joey711.github.io/phyloseq/import-data) options if you processed your raw sequence data with a different pipeline.

The samples were collected from the Western basin of Lake Erie between May and November 2014 at three different locations. The goal of this dataset was to understand how the bacterial community in Lake Erie shifts during toxic [algal blooms](http://www.glerl.noaa.gov/res/HABs_and_Hypoxia/) caused predominantly by a genus of cyanobacteria called [Microcystis](https://en.wikipedia.org/wiki/Microcystis). 
      
In this tutorial, we will learn how to import an OTU table and sample metadata into R with the Phyloseq package. We will perform some basic exploratory analyses, examining the taxonomic composition of our samples, and visualizing the dissimilarity between our samples in a low-dimensional space using ordinations. Lastly, we will estimate the alpha diversity (richness and evenness) of our samples.

# Libraries
```{r load libraries, warning = FALSE, message = FALSE}
#Load libraries
library(ggplot2)
library(vegan)
library(dplyr)
library(scales)
library(grid)
library(reshape2)
library(phyloseq)
```

```{r}
# Set working directory
setwd("~/chabs/miseq_may2015/analysis/")

# Source code files
# miseqR.R can be found in this repository
source("~/git_repos/MicrobeMiseq/R/miseqR.R")

# Set plotting theme
theme_set(theme_bw())

```

# Data import

First, we will import the mothur shared file, consensus taxonomy file, 
and our sample metadata and store them in one phyloseq object.
By storing all of our data structures together in one object 
we can easily interface between each of the structures. 
For example, as we will see later, we can use criteria in the 
sample metadata to select certain samples from the OTU table. 

```{r mothur import}

# Assign variables for imported data
sharedfile = "mothur/chabs.shared"
taxfile = "mothur/chabs-silva.taxonomy"
mapfile = "other/habs_metadata_cleaned.csv"

# Import mothur data
mothur_data <- import_mothur(mothur_shared_file = sharedfile,
  mothur_constaxonomy_file = taxfile)

# Import sample metadata
map <- read.csv(mapfile)
```
The sample metadata is just a basic csv with columns for sample attributes.
Here is a preview of what the sample metadata looks like. As you can see, there is one column
called SampleID with the names of each of the samples. The remaining columns contain information on
the environmental or sampling conditions related to each sample.
```{r}
head(map)
```

We convert this dataframe into phyloseq format with a simple constructor.
The only formatting required to merge the sample data into a phyloseq object is that the 
rownames must match the sample names in your shared and taxonomy files. 
```{r}
map <- sample_data(map)

# Assign rownames to be Sample ID's
rownames(map) <- map$SampleID
```

We need to merge our metadata into our phyloseq object. 
```{r}
# Merge mothurdata object with sample metadata
moth_merge <- merge_phyloseq(mothur_data, map)
moth_merge
```

Now we have a phyloseq object called moth.merge. If we wanted to, we could also 
add a phylogenetic tree or a fasta with OTU representative sequences into this object.
At anytime, we can print out the data structures stored in a phyloseq object to 
quickly view its contents.

Before we move on with analysis, we need to do some basic reformatting and filtering. 

What are the column names of our taxonomy file? 

```{r}
colnames(tax_table(moth_merge))
```

These taxonomy names are not helpful, so let's rename them

```{r}
colnames(tax_table(moth_merge)) <- c("Kingdom", "Phylum", "Class", 
  "Order", "Family", "Genus")
```
    
Now, let's filter out samples we don't want to include in our analysis
such as the extraction and pcr blanks (We can look at these later to see what's there)
          
Note: there is a column in my metadata named "Type"      
The "." that appears in the prune_taxa command is used to refer to the 
data object that we are piping in (the phyloseq object with non-samples removed)
```{r}
moth_sub <- moth_merge %>%
  subset_samples(Type == "sample") %>%
  prune_taxa(taxa_sums(.) > 0, .)
```

Now we will filter out Eukaryotes, Archaea, chloroplasts and mitochondria,
because we only intended to amplify bacterial sequences. 
You may have done this filtering already in mothur, but it's good to check
you don't have anything lurking in the taxonomy table. I like to keep these organisms
in my dataset when running mothur because they are easy enough to remove with Phyloseq
and sometimes I'm interested in exploring them. 
```{r}
erie <- moth_sub %>%
  subset_taxa(
    Kingdom == "Bacteria" &
    Family  != "mitochondria" &
    Class   != "Chloroplast"
  )

erie
```

# Sample summary

As a first analysis, we will look at the distribution of read counts from our samples

```{r}
# Make a data frame with a column for the read counts of each sample
sample_sum_df <- data.frame(sum = sample_sums(erie))

# Histogram of sample read counts
ggplot(sample_sum_df, aes(x = sum)) + 
  geom_histogram(color = "black", fill = "indianred", binwidth = 2500) +
  ggtitle("Distribution of sample sequencing depth") + 
  xlab("Read counts") +
  theme(axis.title.y = element_blank())

# mean, max and min of sample read counts
smin <- min(sample_sums(erie))
smean <- mean(sample_sums(erie))
smax <- max(sample_sums(erie))

```
The minimum sample read count is `r smin`          
The mean sample read count is `r round(smean, 1)`           
The max sample read count is `r smax`      



# Stacked barplots

Let's make a stacked barplot of Phyla to get a sense of the community composition in these samples. 

Since this is not a quantitative analysis, and since we have more Phyla in this dataset than we can reasonably distinguish colors (43!), we will prune out low abundance taxa and only include Phyla that contribute more than 2% of the relative abundance of each sample. Depending on your dataset and the taxonomic level you are depicting, you can adjust this prune parameter. In later analyses, we will of course included these taxa, but for now they will just clutter our plot.


```{r composition barplot, fig.height=10, fig.width=14}
# melt to long format (for ggploting) 
# prune out phyla below 2% in each sample

erie_phylum <- erie %>%
  tax_glom(taxrank = "Phylum") %>%                     # agglomerate at phylum level
  transform_sample_counts(function(x) {x/sum(x)} ) %>% # Transform to rel. abundance
  psmelt() %>%                                         # Melt to long format
  filter(Abundance > 0.02) %>%                         # Filter out low abundance taxa
  arrange(Phylum)                                      # Sort data frame alphabetically by phylum
```

```{r echo = FALSE}
# Function to order date levels correctly
order_dates <- function(df) {
  df$Date <- factor(df$Date, 
    levels = c("6/16","6/30","7/8","7/14","7/21",
      "7/29","8/4","8/11","8/18","8/25","9/2","9/8","9/15",
      "9/23","9/29","10/6","10/15","10/20","10/27"))
  return(df)
}

# Fix the order of dates in the data frame
erie_phylum <- order_dates(erie_phylum)
```

```{r}
  
# Set colors for plotting
phylum_colors <- c(
  "#CBD588", "#5F7FC7", "orange","#DA5724", "#508578", "#CD9BCD",
   "#AD6F3B", "#673770","#D14285", "#652926", "#C84248", 
  "#8569D5", "#5E738F","#D1A33D", "#8A7C64", "#599861"
)


# Plot 
ggplot(erie_phylum, aes(x = Date, y = Abundance, fill = Phylum)) + 
  facet_grid(Station~.) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = phylum_colors) +
  scale_x_discrete(
    breaks = c("7/8", "8/4", "9/2", "10/6"),
    labels = c("Jul", "Aug", "Sep", "Oct"), 
    drop = FALSE
  ) +
  # Remove x axis title
  theme(axis.title.x = element_blank()) + 
  #
  guides(fill = guide_legend(reverse = TRUE, keywidth = 1, keyheight = 1)) +
  ylab("Relative Abundance (Phyla > 2%) \n") +
  ggtitle("Phylum Composition of Lake Erie \n Bacterial Communities by Sampling Site") 
        
```

This plot was created using [facets](http://www.cookbook-r.com/Graphs/Facets_(ggplot2)/) to seperate samples along the y axis by sampling station. This is a great feature of ggplot. 

Notice that each sample doesn't fully add up to 1. This reflects the rare phyla 
that were removed. If you want your plot to look like everything adds up, you can 
add position = "fill" to the geom_bar() command. 

# Unconstrained Ordinations

One of the best exploratory analyses for amplicon data is unconstrained ordinations.
Here we will look at ordinations of our full community samples. We will use the scale_reads()
function in miseqR.R to scale to the smallest library size, which is the default.
If you want to scale to another depth, you can do so by setting the "n" argument. 
```{r}
# Scale reads to even depth 
erie_scale <- erie %>%
  scale_reads(round = "round") 

# Fix month levels in sample_data
sample_data(erie_scale)$Month <- factor(
  sample_data(erie_scale)$Month, 
  levels = c("June", "July", "August", "September", "October")
)


# Ordinate
erie_pcoa <- ordinate(
  physeq = erie_scale, 
  method = "PCoA", 
  distance = "bray"
)

# Plot 
plot_ordination(
  physeq = erie_scale,
  ordination = erie_pcoa,
  color = "Month",
  shape = "Station",
  title = "PCoA of Lake Erie bacterial Communities"
) + 
  scale_color_manual(values = c("#a65628", "red", "#ffae19",
    "#4daf4a", "#1919ff", "darkorchid3", "magenta")
  ) +
  geom_point(aes(color = Month), alpha = 0.7, size = 4) +
  geom_point(colour = "grey90", size = 1.5) 
    
```

Let's try an NMDS instead. For NMDS plots it's important to set a seed since the starting positions of samples in the alogrithm is random.

Important: if you calculate your bray-curtis distance metric "in-line" it will perform a square root transformation and 
Wisconsin double standardization. If you don't want this, you can calculate your bray-curtis distance separately

```{r}
set.seed(1)

# Ordinate
erie_nmds <- ordinate(
  physeq = erie_scale, 
  method = "NMDS", 
  distance = "bray"
)

# Plot 
plot_ordination(
  physeq = erie_scale,
  ordination = erie_nmds,
  color = "Month",
  shape = "Station",
  title = "NMDS of Lake Erie bacterial Communities"
) + 
  scale_color_manual(values = c("#a65628", "red", "#ffae19",
    "#4daf4a", "#1919ff", "darkorchid3", "magenta")
  ) +
  geom_point(aes(color = Month), alpha = 0.7, size = 4) +
  geom_point(colour = "grey90", size = 1.5) 

```

NMDS plots attempt to show **ordinal** distances between samples as accurately as possible in two dimensions. It is important to report the stress of these plots, because a high stress value means that the algorithm had a hard time representing the distances between samples in 2 dimensions. The stress of this plot was OK - it was .148 (generally anything below .2 is considered acceptable). However, the PCoA for this data was able to show a lot of variation in just two dimensions, and it shows the temporal trends in this dataset better, so we will stick with that plot. 

# Permanova

Here is an example of how to run a permanova test using the adonis function in vegan.
In this example we are testing the hypothesis that the three stations we collected samples
from have different centroids 

```{r}
set.seed(1)

# Calculate bray curtis distance matrix
erie_bray <- phyloseq::distance(erie_scale, method = "bray")

# make a data frame from the sample_data
sampledf <- data.frame(sample_data(erie))

# Adonis test
adonis(erie_bray ~ Station, data = sampledf)

# Homogeneity of dispersion test
beta <- betadisper(erie_bray, sampledf$Station)
permutest(beta)

```
This output tells us that our adonis test is significant so we can reject the null hypothesis that our three sites have the same centroid.

Additionally, our betadisper results are not significant, meaning we cannot reject the null hypothesis that our groups have the same dispersions. This means we can be more confident that our adonis result is a real result, and not due to differences in group dispersions

There is a lot more analysis that can be done here. We could use a distance metric other than Bray-curtis, we could test different grouping variables, or we could create a more complex permanova by testing a model that combines multiple variables. Unfortunately, there are currently no [post-hoc tests](https://stat.ethz.ch/pipermail/r-sig-ecology/2012-November/003364.html) developed for adonis.


# Constrained Ordinations
Above we used unconstrained ordinations (PCoA, NMDS) to show relationships between samples in low dimensions. We can use a constrained ordination to see how environmental variables are associated with these changes in community composition. We constrain the ordination axes to linear combinations of environmental variables. We then plot the  environmental scores onto the ordination 

```{r}

# Remove data points with missing metadata
erie_not_na <- erie_scale %>%
  subset_samples(
    !is.na(Phycocyanin) & 
	  !is.na(SRP) &
	  !is.na(pH) & 
	  !is.na(ParMC) & 
	  !is.na(H2O2)
  )
	
bray_not_na <- phyloseq::distance(physeq = erie_not_na, method = "bray")

							
# CAP ordinate
cap_ord <- ordinate(
	physeq = erie_not_na, 
	method = "CAP",
	distance = bray_not_na,
	formula = ~ ParMC + Nitrate + SRP + Phycocyanin + Ammonia + pH + H2O2
)

# CAP plot
cap_plot <- plot_ordination(
  physeq = erie_not_na, 
  ordination = cap_ord, 
	color = "Month", 
	axes = c(1,2)
) + 
	aes(shape = Station) + 
	geom_point(aes(colour = Month), alpha = 0.4, size = 4) + 
	geom_point(colour = "grey90", size = 1.5) + 
	scale_color_manual(values = c("#a65628", "red", "#ffae19", "#4daf4a", 
		"#1919ff", "darkorchid3", "magenta")
	)


# Now add the environmental variables as arrows
arrowmat <- vegan::scores(cap_ord, display = "bp")

# Add labels, make a data.frame
arrowdf <- data.frame(labels = rownames(arrowmat), arrowmat)

# Define the arrow aesthetic mapping
arrow_map <- aes(xend = CAP1, 
	yend = CAP2, 
	x = 0, 
	y = 0, 
	shape = NULL, 
	color = NULL, 
	label = labels)

label_map <- aes(x = 1.3 * CAP1, 
	y = 1.3 * CAP2, 
	shape = NULL, 
	color = NULL, 
	label = labels)

arrowhead = arrow(length = unit(0.02, "npc"))

# Make a new graphic
cap_plot + 
  geom_segment(
    mapping = arrow_map, 
  	size = .5, 
  	data = arrowdf, 
  	color = "gray", 
  	arrow = arrowhead
  ) + 
  geom_text(
    mapping = label_map, 
  	size = 4,  
  	data = arrowdf, 
  	show.legend = FALSE
  )

```

Do a permutational ANOVA on constrained axes used in ordination

```{r}

anova(cap_ord)

```
# Alpha Diversity

Estimating alpha diversity of microbial communities is [problematic](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC93182/) no matter what you do. My best stab at it is to subsample the libraries with replacement to estimate the species abundance of the real population while standardizing sampling effort. 


```{r}

min_lib <- min(sample_sums(erie))

```
We will subsample to `r min_lib`, the minimum number of reads. 
We will repeat this 100 times and average the diversity estimates from each trial. 

```{r, cache=TRUE}
# Initialize matrices to store richness and evenness estimates
nsamp = nsamples(erie)
trials = 100

richness <- matrix(nrow = nsamp, ncol = trials)
row.names(richness) <- sample_names(erie)

evenness <- matrix(nrow = nsamp, ncol = trials)
row.names(evenness) <- sample_names(erie)

# It is always important to set a seed when you subsample so your result is replicable 
set.seed(3)

for (i in 1:100) {
  # Subsample
  r <- rarefy_even_depth(erie, sample.size = min_lib, verbose = FALSE, replace = TRUE)
  
  # Calculate richness
  rich <- as.numeric(as.matrix(estimate_richness(r, measures = "Observed")))
  richness[ ,i] <- rich
  
  # Calculate evenness
  even <- as.numeric(as.matrix(estimate_richness(r, measures = "InvSimpson")))
  evenness[ ,i] <- even
}
```

Let's calculate the mean and standard deviation per sample for observed richness and inverse simpson's index and store those values in a dataframe.

```{r}
# Create a new dataframe to hold the means and standard deviations of richness estimates
SampleID <- row.names(richness)
mean <- apply(richness, 1, mean)
sd <- apply(richness, 1, sd)
measure <- rep("Richness", nsamp)
rich_stats <- data.frame(SampleID, mean, sd, measure)

# Create a new dataframe to hold the means and standard deviations of evenness estimates
SampleID <- row.names(evenness)
mean <- apply(evenness, 1, mean)
sd <- apply(evenness, 1, sd)
measure <- rep("Inverse Simpson", nsamp)
even_stats <- data.frame(SampleID, mean, sd, measure)

```

Now we will combine our estimates for richness and evenness into one dataframe
```{r}
alpha <- rbind(rich_stats, even_stats)
```

Let's add the sample metadata into this dataframe using the merge() command 
```{r}
s <- data.frame(sample_data(erie))
alphadiv <- merge(alpha, s, by = "SampleID") 
```

Lastly, we will reorder some factors in this dataset before plotting them
```{r}
alphadiv <- order_dates(alphadiv)
```

Finally, we will plot the two alpha diversity measures in a timeseries using a facet

```{r}

ggplot(alphadiv, aes(x = Date, y = mean, color = Station, group = Station, shape = Station)) +
  geom_point(size = 2) + 
  geom_line(size = 0.8) +
  facet_wrap(~measure, ncol = 1, scales = "free") +
  scale_color_manual(values = c("#E96446", "#302F3D", "#87CEFA")) +
  scale_x_discrete(
    breaks = c("7/8", "8/4", "9/2", "10/6"),
    labels = c("Jul", "Aug", "Sep", "Oct"), 
    drop = FALSE
  ) +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank()
  )

```

           

# Session info
```{r}
sessionInfo()


```


