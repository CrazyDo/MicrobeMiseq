## mothur_to_fwdb.batch
# mothur batch script to classify OTUs with the freshwater data base
# Copied over from:  FWGG_SerialClassification_Manual_Draft_042514 that was obtained from https://github.com/mcmahon-uw/FWMFG
# Notes and edits by Vincent Denef and Marian Schmidt on Nov. 3, 2015
# Additional edits by Michelle Berry on Nov. 6, 2015
# few more edits by Vincent Denef on Nov 6, 2015


## Set working directory
set.dir(output=/scratch/lsa_fluxm/vdenef/Sequence_data/Combined_LM13DNAcDNA_mothur_reclassification/realignwholedb+reclass/)
set.dir(tempdefault=/scratch/lsa_fluxm/vdenef/Databases/ssu_rRNA/Mothur/)

##set current files - for jgi data we already have contigs generated by jgi
set.current(name=fasta=jgi16S40kitagger.trim.contigs.fasta)
set.current(group=jgi16S40kitagger.contigs.groups)
set.current(processors=10)

## now run standard mothur commands, using silva_nr to align so as to avoid unassigned issues when using the seed database
summary.seqs(fasta=current)
screen.seqs(fasta=current, group=current, summary=current, maxambig=0, maxlength=275, minlength=250, maxhomop=8)
summary.seqs(fasta=current)
unique.seqs()
count.seqs(name=current, group=current)
align.seqs(fasta=current, reference=silva.nr_v119.pcr.v4.align)
screen.seqs(fasta=current, count=current, start=1968, end=11550)
summary.seqs(count=current)
filter.seqs(fasta=current, vertical=T, trump=.)
unique.seqs(fasta=current, count=current)
pre.cluster(fasta=current, count=current, diffs=2)
chimera.uchime(fasta=current, count=current, dereplicate=t)
remove.seqs(fasta=current, accnos=current)
summary.seqs(count=current)

#classify step 1, using Freshwater db of Newton et al.
# I corrected greengenes formatted names from FWDB (remove *__ before taxonomy name) to "Silva" names and made new file FW_train_2012July_silvaformat.taxonomy
classify.seqs(fasta=current, count=current, reference=FW_train_2012July.fasta, taxonomy=FW_train_2012July_silvaformat.taxonomy, cutoff=80)

# Select all that DO match FWDB
system(grep -v "^[^;]*;[^;]*;[^;]*;[^;]*;unclassified" jgi16S40kitagger.trim.contigs.good.unique.good.filter.unique.precluster.pick.silvaformat.wang.taxonomy > matched_FW.80.taxonomy)

# Select all that do NOT match FWDB
system(grep "^[^;]*;[^;]*;[^;]*;[^;]*;unclassified" jgi16S40kitagger.trim.contigs.good.unique.good.filter.unique.precluster.pick.silvaformat.wang.taxonomy > not_matched_toFWDB.taxonomy)

# Retain read names of reads that do NOT match FWDB
system(cut -f 1 not_matched_toFWDB.taxonomy > not_matched_toFWDB_readnames.taxonomy.list)

# Generate a fasta file based on the list of sequences that do NOT match FWDB
# use the script called "screen_list.pl" that Vincent sent on Nov.4
system(perl /home/vdenef/software/scripts/perl/screen_list.pl not_matched_toFWDB_readnames.taxonomy.list jgi16S40kitagger.trim.contigs.good.unique.good.filter.unique.precluster.pick.fasta keep > unclassified_Silva.fasta)

# classify step 2, the reads NOT classified by FWDB, using Silva_NR and remove unwanted seqs
classify.seqs(fasta=unclassified_Silva.fasta, reference=silva.nr_v119.pcr.v4.align, taxonomy=silva.nr_v119.tax, cutoff=80)

###  Insert file name from above command into the below commands
# make a copy of "unclassified_Silva.nr_v119.wang.taxonomy" and name it "silva.assigned.80.taxonomy"
system(cp unclassified_Silva.nr_v119.wang.taxonomy silva.assigned.80.taxonomy)

# Concatenate the FWDB matches to the SilvaDB matches into one file called "final.FWDB.Silva.taxonomy"
system(cat matched_FW.80.taxonomy silva.assigned.80.taxonomy > final.FWDB.Silva.taxonomy)

# Cluster sequences into OTUs. To save memory/time we first split sequences by taxlevel 4 (order) and then cluster from there. Read mothur wiki for more info. 
remove.lineage(fasta=current, count=current, taxonomy=final.FWDB.Silva.taxonomy, taxon=Chloroplast-Mitochondria-unknown-Archaea-Eukaryota)
cluster.split(fasta=current, count=current, taxonomy=current, splitmethod=classify, taxlevel=4, cutoff=0.15)
summary.seqs(count=current)

# Determine how many sequences are in each OTU, using a .03 similarity cutoff 
make.shared(list=current, count=current, label=0.03)
summary.seqs(count=current)

# Generate a consensus taxonomy for each OTU
classify.otu(list=current, count=current, taxonomy=final.FWDB.Silva.taxonomy, label=0.03)
summary.seqs(count=current)

